{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: extracting features from the test data...\n",
      "preprocessing complete\n",
      "[2 2 1 ..., 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Nov 29, 2017\n",
    "Program : Tweets extraction and preprocessing\n",
    "References : https://stackoverflow.com/questions/8376691/how-to-remove-hashtag-user-link-of-a-tweet-using-regular-expression\n",
    "             http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-pyx\n",
    "@author: Ritesh Tawde\n",
    "'''\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "from imblearn.over_sampling.random_over_sampler import RandomOverSampler\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "def testing_classifiers(training_data, training_labels, testing_data, testing_labels):\n",
    "    \n",
    "    params = {'objective': 'binary:logistic',\n",
    "         'eta': 0.02,\n",
    "         'silent': True,\n",
    "         'max_depth': 5,\n",
    "         'subsample': 0.8,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'eval_metric': 'auc',\n",
    "         'learning_rate' : 0.05,\n",
    "         'n_estimators' : 300\n",
    "         }\n",
    "    \n",
    "    # result frame\n",
    "    result = pd.DataFrame()\n",
    "    result['target'] = np.zeros_like(testing_labels)\n",
    "\n",
    "    xg_model = xgb.XGBClassifier(objective='binary:logistic', scale_pos_weight = 5, colsample_bytree = 0.8, max_depth = 5, n_estimators=300, learning_rate=0.001).fit(training_data, training_labels)\n",
    "    xgb_predict = xg_model.predict(testing_data)\n",
    "    print(xgb_predict)\n",
    "    return xgb_predict\n",
    "\t\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # object for one hot encoder\n",
    "    enc = OneHotEncoder()\n",
    "    training_data = pd.read_csv(\"training.csv\")\n",
    "    testing_data = pd.read_csv(\"testing.csv\")\n",
    "    \n",
    "    # url present/absent mapping\n",
    "    training_data['is_url_present'] = np.where(training_data['is_url_present'] == True, 1, 0)\n",
    "    # profiling gender of an author\n",
    "    \n",
    "    # count vectorizer for training and testing data\n",
    "    training_tweets = training_data['tweet_text']\n",
    "    testing_tweets = testing_data['tweet_text']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    training_doc_term = coo_matrix(vectorizer.fit_transform(training_tweets.values.astype('U')))\n",
    "    testing_doc_term = coo_matrix(vectorizer.transform(testing_tweets.values.astype('U')))\n",
    "    \n",
    "    # classifying age class imbalanced\n",
    "    \n",
    "    training_labels = training_data['tweet_age']\n",
    "    testing_labels = testing_data['tweet_age']\n",
    "    \n",
    "    training_rest = np.vstack((np.array(training_data['tweet_gender']), np.array(training_data['tweet_tags']), np.array(training_data['is_url_present'])))\n",
    "    training_rest = training_rest.T\n",
    "    training_rest = coo_matrix(enc.fit_transform(training_rest))\n",
    "    entire_training_frame = hstack([training_doc_term, training_rest])\n",
    "\n",
    "    print('[INFO]: extracting features from the test data...')\n",
    "    testing_rest = np.vstack((np.array(testing_data['tweet_gender']), np.array(testing_data['tweet_tags']), np.array(testing_data['is_url_present'])))\n",
    "    testing_rest = testing_rest.T\n",
    "    testing_rest = coo_matrix(enc.transform(testing_rest))\n",
    "    entire_testing_frame = hstack([testing_doc_term, testing_rest])\n",
    "    # entire_testing_frame = np.concatenate((testing_doc_term.todense(), testing_rest.todense()), axis = 1)\n",
    "    print('preprocessing complete')\n",
    "    \n",
    "    # based on gender as response variable\n",
    "    ret_labels = testing_classifiers(entire_training_frame, training_labels, entire_testing_frame, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52629"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ret_predict == testing_labels)\n",
    "len(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.325770962777\n",
      "Classification report :               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.31      0.23      3692\n",
      "          1       0.34      0.87      0.49     18420\n",
      "          2       0.00      0.00      0.00     21055\n",
      "          3       0.00      0.00      0.00      8989\n",
      "          4       0.00      0.00      0.00       473\n",
      "\n",
      "avg / total       0.13      0.33      0.19     52629\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer Valued Customer\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#34675\n",
    "#35680/52629\n",
    "#np.sum(testing_labels == 0)\n",
    "accuracy_score = metrics.accuracy_score(testing_labels, ret_predict)\n",
    "print(accuracy_score)\n",
    "print(\"Classification report : \", metrics.classification_report(testing_labels, ret_predict))\n",
    "conf_matrix = metrics.confusion_matrix(testing_labels, ret_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92059"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels = training_data['tweet_age']\n",
    "testing_labels = testing_data['tweet_age']\n",
    "len(training_labels[training_labels == 2]) + len(testing_labels[testing_labels == 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
